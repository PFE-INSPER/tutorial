{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7a70ea12",
   "metadata": {},
   "source": [
    "# Enriquecimento dos Dados\n",
    "\n",
    "Nesse arquivo serão gerados os seguintes enriquecimentos de para cada noticia do dataset da Folha de São Paulo\n",
    "\n",
    "- categories\n",
    "- concepts\n",
    "- keywords\n",
    "- sentiment\n",
    "- entities\n",
    "- classification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "37fa5d5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcdec985",
   "metadata": {},
   "source": [
    "## Carrega e limpa dataset noticias Folha\n",
    "\n",
    "link do dataset: https://www.kaggle.com/marlesson/news-of-the-site-folhauol\n",
    "\n",
    "conferir nome do arquivo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "109d5689",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>date</th>\n",
       "      <th>category</th>\n",
       "      <th>subcategory</th>\n",
       "      <th>link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Lula diz que está 'lascado', mas que ainda tem...</td>\n",
       "      <td>Com a possibilidade de uma condenação impedir ...</td>\n",
       "      <td>2017-09-10</td>\n",
       "      <td>poder</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://www1.folha.uol.com.br/poder/2017/10/192...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>'Decidi ser escrava das mulheres que sofrem', ...</td>\n",
       "      <td>Para Oumou Sangaré, cantora e ativista malines...</td>\n",
       "      <td>2017-09-10</td>\n",
       "      <td>ilustrada</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://www1.folha.uol.com.br/ilustrada/2017/10...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Três reportagens da Folha ganham Prêmio Petrob...</td>\n",
       "      <td>Três reportagens da Folha foram vencedoras do ...</td>\n",
       "      <td>2017-09-10</td>\n",
       "      <td>poder</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://www1.folha.uol.com.br/poder/2017/10/192...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Filme 'Star Wars: Os Últimos Jedi' ganha trail...</td>\n",
       "      <td>A Disney divulgou na noite desta segunda-feira...</td>\n",
       "      <td>2017-09-10</td>\n",
       "      <td>ilustrada</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://www1.folha.uol.com.br/ilustrada/2017/10...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CBSS inicia acordos com fintechs e quer 30% do...</td>\n",
       "      <td>O CBSS, banco da holding Elopar dos sócios Bra...</td>\n",
       "      <td>2017-09-10</td>\n",
       "      <td>mercado</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://www1.folha.uol.com.br/mercado/2017/10/1...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  Lula diz que está 'lascado', mas que ainda tem...   \n",
       "1  'Decidi ser escrava das mulheres que sofrem', ...   \n",
       "2  Três reportagens da Folha ganham Prêmio Petrob...   \n",
       "3  Filme 'Star Wars: Os Últimos Jedi' ganha trail...   \n",
       "4  CBSS inicia acordos com fintechs e quer 30% do...   \n",
       "\n",
       "                                                text        date   category  \\\n",
       "0  Com a possibilidade de uma condenação impedir ...  2017-09-10      poder   \n",
       "1  Para Oumou Sangaré, cantora e ativista malines...  2017-09-10  ilustrada   \n",
       "2  Três reportagens da Folha foram vencedoras do ...  2017-09-10      poder   \n",
       "3  A Disney divulgou na noite desta segunda-feira...  2017-09-10  ilustrada   \n",
       "4  O CBSS, banco da holding Elopar dos sócios Bra...  2017-09-10    mercado   \n",
       "\n",
       "  subcategory                                               link  \n",
       "0         NaN  http://www1.folha.uol.com.br/poder/2017/10/192...  \n",
       "1         NaN  http://www1.folha.uol.com.br/ilustrada/2017/10...  \n",
       "2         NaN  http://www1.folha.uol.com.br/poder/2017/10/192...  \n",
       "3         NaN  http://www1.folha.uol.com.br/ilustrada/2017/10...  \n",
       "4         NaN  http://www1.folha.uol.com.br/mercado/2017/10/1...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news = pd.read_csv('news.csv')\n",
    "\n",
    "news = news.dropna(subset=['text', 'title', 'date', 'category'])\n",
    "news = news[news[\"title\"] != \"Aviso\"]\n",
    "news = news[news[\"title\"] != \"Aviso de férias\"]\n",
    "news = news[news[\"text\"].str.len() >= 60]\n",
    "news.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dabcf452",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "## Login NLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2aa9789c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from ibm_watson import NaturalLanguageUnderstandingV1\n",
    "from ibm_watson.natural_language_understanding_v1 import * \n",
    "from ibm_cloud_sdk_core.authenticators import IAMAuthenticator\n",
    "\n",
    "apikey = 'HhNXvrfHCVgWjgCSlcAIzi-fW8_zoCyCI2FS6dl_dcMn'\n",
    "url = 'https://api.us-south.natural-language-understanding.watson.cloud.ibm.com/instances/6f5ec2bb-44da-4ab6-babf-8a7527f92256'\n",
    "\n",
    "authenticator = IAMAuthenticator(apikey)\n",
    "nlu = NaturalLanguageUnderstandingV1(\n",
    "    version='2021-08-01',\n",
    "    authenticator=authenticator\n",
    ")\n",
    "\n",
    "nlu.set_service_url(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc25f44e",
   "metadata": {},
   "source": [
    "## Modelo\n",
    "\n",
    "Para utilizar a feature de classificação do NLU é necessario enviar os dados de treinamento através da função model_create() e esperar aproximadamente 30 minutos para a conclusão, é possivel observar a etapa atual através da função model_get_status().\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9e757445",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_create(training_data_filename = 'training_data.json'):\n",
    "    with open(training_data_filename, 'rb') as file:\n",
    "        model = nlu.create_classifications_model(language='pt', training_data=file, training_data_content_type='application/json', name='pfe-model', model_version='1.0.1').get_result()\n",
    "        \n",
    "        print(\"Created a NLU Classifications model:\")\n",
    "        print(json.dumps(model, indent=4))\n",
    "\n",
    "def model_get_status(model_id):\n",
    "    model_to_view = nlu.get_classifications_model(model_id=model_id).get_result()\n",
    "\n",
    "    print(\"Information about the created NLU Classifications model:\")\n",
    "    print(json.dumps(model_to_view, indent=4))\n",
    "\n",
    "def model_analyze(model_id, text):\n",
    "    analysis = nlu.analyze(text=text, features=Features(classifications=ClassificationsOptions(model=model_id))).get_result()\n",
    "\n",
    "    print(\"Analysis response from trained NLU Classifications model:\")\n",
    "    print(json.dumps(analysis, indent=4))\n",
    "\n",
    "# Deleta o modelo\n",
    "def model_delete(model_id):\n",
    "    deleted_model = nlu.delete_classifications_model(model_id=model_id)\n",
    "    updated_models_list = nlu.list_classifications_models().get_result()\n",
    "\n",
    "    print(\"The NLU Classifications model created in this tutorial has been deleted:\")\n",
    "    print(json.dumps(updated_models_list, indent=4))\n",
    "\n",
    "def get_model_id():\n",
    "    res = nlu.list_classifications_models().get_result()\n",
    "    m_id = res['models'][0]['model_id']\n",
    "    print(f'Model id: {m_id}')\n",
    "    return m_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2293a00d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created a NLU Classifications model:\n",
      "{\n",
      "    \"name\": \"pfe-model\",\n",
      "    \"user_metadata\": null,\n",
      "    \"language\": \"pt\",\n",
      "    \"description\": null,\n",
      "    \"model_version\": \"1.0.1\",\n",
      "    \"version\": \"1.0.1\",\n",
      "    \"workspace_id\": null,\n",
      "    \"version_description\": null,\n",
      "    \"status\": \"starting\",\n",
      "    \"notices\": [],\n",
      "    \"model_id\": \"d5061e6c-9a7c-4295-a6ea-608208f5f9b6\",\n",
      "    \"features\": [\n",
      "        \"classifications\"\n",
      "    ],\n",
      "    \"created\": \"2021-11-22T13:52:54Z\",\n",
      "    \"last_trained\": \"2021-11-22T13:52:54Z\",\n",
      "    \"last_deployed\": null\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "model_create() # cria modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a58a74a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model id: d5061e6c-9a7c-4295-a6ea-608208f5f9b6\n"
     ]
    }
   ],
   "source": [
    "model_id = get_model_id()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0cd2c7b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information about the created NLU Classifications model:\n",
      "{\n",
      "    \"name\": \"pfe-model\",\n",
      "    \"user_metadata\": null,\n",
      "    \"language\": \"pt\",\n",
      "    \"description\": null,\n",
      "    \"model_version\": \"1.0.1\",\n",
      "    \"version\": \"1.0.1\",\n",
      "    \"workspace_id\": null,\n",
      "    \"version_description\": null,\n",
      "    \"status\": \"starting\",\n",
      "    \"notices\": [],\n",
      "    \"model_id\": \"d5061e6c-9a7c-4295-a6ea-608208f5f9b6\",\n",
      "    \"features\": [\n",
      "        \"classifications\"\n",
      "    ],\n",
      "    \"created\": \"2021-11-22T13:52:54Z\",\n",
      "    \"last_trained\": \"2021-11-22T13:52:54Z\",\n",
      "    \"last_deployed\": null\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "model_get_status(model_id) # verifica status \n",
    "# model_delete(model_id) # deleta modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a9655fb",
   "metadata": {},
   "source": [
    "## Passando os dados pelo NLU\n",
    "\n",
    "Na celula abaixo o texto de cada notícia é enviado para a API do NLU para que possa ser feita a análise. Foi dividido em duas partes por motivos de limitações na quantidade de texto permitida para a análise de classificação do modelo.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "87bc5018",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# ######################################## #\n",
    "# Selecionar range do dataset de noticias  #\n",
    "# ######################################## #\n",
    "\n",
    "for i in tqdm(range(0, 100_000)):    \n",
    "    title = news.values[i][0]\n",
    "    text = news.values[i][1]\n",
    "    date = news.values[i][2]\n",
    "    category = news.values[i][3]\n",
    "    subcategory = news.values[i][4]\n",
    "    link = news.values[i][5]\n",
    "        \n",
    "    ##  Classificação modelo \n",
    "    n = 1500 # chunk length\n",
    "    chunks = [text[i:i+n] for i in range(0, len(text), n)]\n",
    "    len_chunks = len(chunks)\n",
    "    \n",
    "    error = len_chunks == 1 and len(chunks[0]) < 150\n",
    "    if error: continue\n",
    "    \n",
    "    left = 0\n",
    "    right = 0\n",
    "        \n",
    "    for part in chunks:\n",
    "        if len(part) < 150: \n",
    "            len_chunks -= 1\n",
    "            continue\n",
    "            \n",
    "        res_classification = nlu.analyze(\n",
    "            text= str(part),\n",
    "            language= \"pt\",\n",
    "            features= Features(\n",
    "                classifications=ClassificationsOptions(model=model_id)\n",
    "            )).get_result()        \n",
    "        \n",
    "        for classific in res_classification['classifications']:\n",
    "            if classific['class_name'] == \"Direita\":\n",
    "                right += classific['confidence'] \n",
    "            elif classific['class_name'] == \"Esquerda\":\n",
    "                left += classific['confidence']\n",
    "    \n",
    "    if left > right:\n",
    "        polaridade = {'class_name': 'Esquerda', 'confidence': left / len_chunks}\n",
    "    else:\n",
    "        polaridade = {'class_name': 'Direita', 'confidence': right / len_chunks}\n",
    "        \n",
    "    ##  Analise Features do NLU\n",
    "    response = nlu.analyze(\n",
    "        text=text,\n",
    "        language= \"pt\",\n",
    "        features=Features(\n",
    "            categories=CategoriesOptions(limit=3),\n",
    "            concepts=ConceptsOptions(limit=3),\n",
    "            keywords=KeywordsOptions(sentiment=True,emotion=False,limit=3),\n",
    "            sentiment=SentimentOptions(),\n",
    "            entities=EntitiesOptions(sentiment=True,limit=10),\n",
    "        )).get_result()\n",
    "    \n",
    "    file = {\"enrichments\": response,\n",
    "            \"classification\": polaridade,\n",
    "            \"text\": text,\n",
    "            \"title\": title,\n",
    "            \"category\": category,\n",
    "            \"data\": date,\n",
    "            \"link\": link\n",
    "           }\n",
    "    \n",
    "    with open(f\"dados/news_{i}.json\", 'w', encoding=\"utf-8\") as f:\n",
    "        f = json.dump(file, f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2054d5cd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ca0a2e4aaaf2499b20aacfbed62cb2c6cf180f1e5acb3410940b48836e450d74"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
